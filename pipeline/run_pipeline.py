# run_pipeline.py

from ingest_news import fetch_articles
from preprocess_and_chunk import chunk_articles
from embed_chunks import embed_chunks
from store_faiss import store_faiss_index

def run_pipeline():
    print("ðŸ“¥ Step 1: Ingesting news articles...")
    articles = fetch_articles()
    print(f"âœ… Fetched {len(articles)} articles.")

    print("ðŸ§¹ Step 2: Preprocessing and chunking...")
    chunks = chunk_articles(articles)
    print(f"âœ… Generated {len(chunks)} chunks.")

    print("ðŸ”¢ Step 3: Generating embeddings...")
    embedded_chunks = embed_chunks(chunks)
    print("âœ… Embeddings created.")

    print("ðŸ’¾ Step 4: Storing in FAISS index...")
    store_faiss_index(embedded_chunks)
    print("âœ… Stored {0} vectors in FAISS.".format(len(embedded_chunks)))

if __name__ == "__main__":
    run_pipeline()
